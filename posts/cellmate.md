Title: ceLLMate: Sandboxing Browser AI Agents
Date: 2026-09-06
Tags: ucsd, research, security, llm, agent

# ceLLMate: Sandboxing Browser AI Agents

Browser-use agents (BUAs) are emerging as a new class of autonomous agents that interact with web browsers in human-like ways, such as clicking, scrolling, filling forms, and navigating across multiple pages. Examples include [Browser-Use](https://browser-use.com), [Amazon Nova Act](https://nova.amazon.com/act), [OpenAI Operator](https://openai.com/index/introducing-operator), [Google Project Mariner](https://deepmind.google/models/project-mariner), and [Perplexity's Comet](https://www.perplexity.ai/comet). Although these agents empower people to automate repetitive online tasks, they are vulnerable to prompt injections that allow an attacker to trick an agent into performing undesirable actions, such as leaking private information or issuing state-changing requests to the website. The ability of malicious actors to commandeer these agents poses an unprecedented threat to user privacy and web security, demanding urgent development of injection-resistant architectures.

In this post, we introduce a sandboxing framework, [_Cellmate_](https://github.com/earlence-security/cellmate), that restricts the agent's privilege and thereby reduces the blast radius of prompt injection.

## What are BUAs?

A BUA comprises an LLM and a runtime environment. During its execution, the runtime utilizes a browser automation framework, such as [Playwright](https://playwright.dev), to browse and interact with websites like a human.
At the core of a BUA is its agent loop, where the agent iteratively queries an LLM to obtain the next action and performs that action on a browser session. At each step, the agent captures the current state of the webpage, usually including a screenshot and the Document Object Model (DOM); then, it queries an LLM to select an action from a set of predefined actions. The LLM will reply with one or more actions, along with the arguments like the URL to navigate, or the index of the element to click in the DOM tree. This process is repeated until the completion of the task.

<img src="images/sep-2025/bua.png" alt="BUA Diagram" style="zoom: 20%;" />

## Prompt Injection in BUAs

Prompt injection is one of the top security issues in LLM. Akin to stack smashing, in prompt injection attacks, an attacker crafts malicious, deceptive text to manipulate an LLM into performing unintended actions or revealing confidential information.

By design, BUAs inherit the vulnerabilities of their LLM backbone, making them naturally prone to prompt injection attacks. Brave recently uncovered [vulnerabilities in Perplexity's Comet](https://brave.com/blog/comet-prompt-injection): when asked to "summarize a webpage", Comet directly forwarded part of the webpage to its backbone LLM, enabling prompt injection that let attackers take over a user' Perplexity account. [A similar attack](https://embracethered.com/blog/posts/2025/chatgpt-operator-prompt-injection-exploits) has been demonstrated with OpenAI's Operator, where the agent leaks the user's private email address to an attacker-controlled domain.

In both examples, the BUAs are given access to the entire browser session, along with unfettered access to any authenticated user session. Thus, BUAs naturally introduce unprecedented threats where agents can potentially perform any action on the user account and sensitive data.

Beyond their harms, prompt injection attacks are also becoming increasingly practical. Recent research has introduced a growing set of techniques for crafting prompt injection attacks, from handcrafted attacks using linguistic quirks, role-playing, etc., to automated attacks generated by optimization algorithms [7,11,12]. This combination of high impact and low barrier to execution makes the need for effective defenses against prompt injection especially urgent.

## Cellmate Sandboxes BUAs

Cellmate is a sandboxing framework for BUAs that enforces strict boundaries on their behavior, ensuring safety even in worst-case execution scenarios - analogous to process-level sandboxing in system security. Its sandboxing mechanism consists of two components: _policy specification_ and _enforcement_.

### Policy Enforcement

A fundamental challenge in sandboxing BUAs is the _semantic gap_: a concept describing the mismatch between low-level system observations and the high-level semantics that users or policies care about. In the context of BUAs, this gap arises between sequences of UI observations and manipulations that agents operate on and higher-level policies administrators wish to enforce. Because of this gap, writing and enforcing policies directly over UI-level events is brittle and error-prone.

For example, restricting a [browser-use agent](https://browser-use.com) to approved webpages is non-trivial: the agent exposes [19 default tools](https://github.com/browser-use/browser-use/blob/main/browser_use/tools/service.py), and navigation can be achieved in many different ways. As a preliminary test, we placed an access control check on the `go_to_url` tool, but upon encountering a permission denial, the agent bypassed it by chaining `search_google` and `click_element_with_index` (see figure below). 

<img src="images/sep-2025/browser-use.png" alt="Browser-Use bypasses access control on `go_to_url` tool" style="zoom: 20%;" />

The root cause is that the same browser state can be reached through many different action sequences, rendering UI-level policy enforcement brittle and making comprehensive enumeration impractical. Even if we block navigation through both `go_to_url` and `click_element_by_index` via clicking a hyperlink, an attacker could still craft arbitrary JavaScript code beyond simple constructs like `<a href=some_url>`, leaving policy evaluation undefined. Even worse, UIs evolve rapidly and are often intentionally obfuscated by developers. 

These observations lead us to conclude that __complete and stable mediation is difficult to achieve when policies are defined solely on UI-level events.__

We decompose the semantic gap problem into two subproblems:

1. Achieving complete and stable mediation beyond UI-level events.
2. Designing a trusted layer that translates low-level browser actions into high-level semantic meanings.

#### Complete and Stable Mediation

Cellmate enforces policies at the __HTTP request level__. Browser actions ultimately manifest as  HTTP requests: while the Web UI provides a front-end interface, the underlying HTTP requests carry out actual operations on user data. Cellmate represents each browser action as an HTTP request and enforces sandboxing policies at this level. For example, `POST https://gitlab.com/-/user_settings/ssh_keys` corresponds to the semantic action _"add an SSH key for user"_ on GitLab.
This design offers two key benefits:

- __Complete and Stable Mediation.__ Every meaningful action a BUA performs against a web application eventually translates into an HTTP request. For example, page navigation issues a GET request to the main frame, and form submission results in a POST request carrying the form data. By mediating requests, we guarantee that all interactions with a domain are subject to policy checks, regardless of the UI path taken.
- __Context-Independent Enforcement.__ Although different sites may expose diverse and evolving UI structures, their interactions converge to standardized HTTP requests. Operating at this level avoids brittle, site-specific policies tied to fragile UI events.

#### Bridging Semantic Gap

Enforcement at the HTTP level alone is insufficient, because raw requests lack explicit semantic meaning. To bridge this gap, we introduce the concept of an __agent sitemap__, which captures the structure and semantics of a web domain.

Similar to how a traditional sitemap provides a structured map of a website’s pages for users or search engines, an agent sitemap provides a structured map of the actions available on a web application. It serves as the trusted layer that deterministically maps low-level HTTP requests to high-level semantic actions. This enables Cellmate to regulate BUA behavior in a way that mirrors how humans interpret browser actions.

We observe that agent sitemaps must function as trusted entities, as malicious or compromised sitemaps could manipulate BUAs into executing harmful actions. Fortunately, web developers and their security teams represent natural custodians for creating agent sitemaps within their domains. Since they already define and expose functionalities, these stakeholders possess both the technical expertise and strong security incentives to prevent BUAs from compromising user data through prompt injection attacks. The effort required to create an agent sitemap is similar to writing API documentation - a task developers are already familiar with. In essence, __agent sitemaps serve as "API documentation" for BUAs__.

### Policy Specification

For traditional software, policy specifications are typically provided by developers or derived automatically through code analysis. In contrast, BUAs present unique challenges: there is no program or developer - only a natural language instruction from an end user. Moreover, the requirement of least privilege is inherently dynamic. Since an agent's behavior is entirely defined by user prompts, and these prompts vary between sessions, no single static policy can capture the least privilege requirements across all cases. We view these challenges as fundamental to agentic browser use. Our goal is therefore to identify the necessary components to enforce secure browsing for agents.

Cellmate treats each web domain as an application. The developers of trusted domains are motivated to protect sensitive resources and their users’ sessions. Users are similarly motivated to protect their own data but often lack the security expertise or incentives to defend against subtle threats such as prompt injection. To balance these roles, Cellmate requires developers to provide composable __rules__ together with their natural language descriptions. These rules serve as reusable building blocks for constructing task-specific policies. 

Cellmate introduces a policy language expressive enough to capture common sandboxing requirements. Since only users know the specific tasks they wish to perform, they are required to explicitly state their intent. In practice, this means (1) specifying the web domain where the task should be executed, and (2) defining a high-level goal of the task. Cellmate then leverages zero-shot inferences to automatically suggest the minimal set of rules necessary for the user’s task.

We emphasize that securing BUAs requires coordination among all stakeholders. __Existing browsers are designed for human users, not agents.__ By introducing agent-specific browser sessions governed by Cellmate policies and implementing these policies through a browser extension, we ensure that BUAs operate under the minimum privilege necessary to complete their tasks.

### Cellmate Workflow

We now describe the end-to-end workflow in Cellmate.

* __Web Domain Registration.__ Developers of trusted domains (e.g., GitLab) provide two key artifacts: an __agent sitemap__ and a set of __rules__. As discussed earlier, the agent sitemap maps HTTP requests to their semantic meanings, while the rules define permission primitives. End users select from these rules when constructing policies, without needing to understand low-level details.

* __Policy Setup.__ A user begins by providing a task. Before launching the BUA, Cellmate infers which domain(s) the agent must interact with. If the target domain is not already associated with a policy in the local mapping table, Cellmate initiates a __policy binding__ process. It highlights a minimal set of rules inferred from the user prompt, then asks for user confirmation. The user can adjust the policy by enabling or disabling rules. Once confirmed, a new entry is created in the lookup table, and the agent session is bound to the approved set of rules.

* __Policy Enforcement.__ The approved policy is compiled into request-level rules using the domain's agent sitemap. At runtime, Cellmate launches an agent-dedicated browser session and intercepts every HTTP request, enforcing the policy with strict mediation.

<img src="images/sep-2025/cellmate-workflow.png" alt="BUA Architecture Diagram" style="zoom:25%;" />

## Case Study: GitLab

GitLab is a web-based DevOps platform that provides Git repository management, CI/CD pipelines, and project collaboration tools. Currently, a BUA operating with an authenticated GitLab session can be tricked by prompt injection into executing actions unintended by the user. The figure below shows one such attack: the user only intends for the BUA to comment on an issue, but a malicious payload embedded in the issue description instructs the agent to create a deploy token with full account access and exfiltrate it to an attacker-controlled domain. This results in a complete account compromise.

<img src="images/sep-2025/attack-gitlab.png" alt="An example prompt injection attack in a GitLab issue" style="zoom: 60%;" />

With Cellmate, we can enforce a fine-grained sandboxing policy to mitigate these risks. GitLab developers begin by supplying an agent sitemap and a set of rules as follows:

* Example Agent Sitemap

```json
[    
    {
        "semantic_action": "Create new issue note",
        "url": "https://gitlab.com/api/graphql",
        "method": "POST",
        "body": {
            "operationName": "createWorkItemNote",
        },
        "tags": [
            "project",
            "issue",
            "note",
            "create"
        ]
    },
    {
        "semantic_action": "Create a personal access token for a user",
        "url": "https://gitlab.com/-/user_settings/personal_access_tokens*",
        "method": "POST",
        "body": {},
        "tags": [
            "user",
            "personal_access_token",
            "create"
        ]
   },
  ...
]
```

* Example Rules

  * `write_project_issue`

    ```json
    {
        "effect": "allow",
        "match": {
            "tags": [
                "project",
                "issue"
            ]
        },
        "description": "Allow read/write access to project issues."
    }
    ```

  * `write_user_personal_access_token`

    ```json
    {
        "effect": "allow",
        "match": {
            "tags": [
                "user",
                "personal_access_token"
            ]
        },
        "description": "Allow read/write access to user personal access tokens."
    }
    ```

In this example, the BUA only requires permission to comment on a GitLab issue. Thus, the user can simply select the `write_project_issue` rule, which grants write access to issues while restricting all other resources to public read-only access. The resulting policy is generated as follows:

```json
{
    "name": "gitlab_policy",
    "default": "allow_public",
    "domain": [
        "gitlab.com"
    ],
    "rules": [
        {
            "effect": "allow",
            "match": {
                "tags": [
                    "project",
                    "issue"
                ]
            },
            "description": "Allow read/write access to project issues."
        }
    ]
}
```

We verified blocking effectiveness by implementing Cellmate as a browser extension
that intercepts HTTP requests. In controlled tests, 100% of requests to create access tokens were successfully blocked when the `write_user_personal_access_token` rule was disabled. By isolating access to sensitive resources from general ones, Cellmate effectively limits the potential harm of prompt injection to the sandbox's boundaries, ensuring that sensitive user data remains protected.


## Why use Cellmate?

* __System-Level Robustness.__ Existing defenses primarily focus on hardening the model itself, through data pre-processing [5,8,9], fine-tuning [1,2,3,10], or detection [6]. However, these probabilistic defenses can be bypassed by sufficiently strong attacks [12]. Cellmate takes a defense-in-depth approach: by enforcing system-level policies over the agent's browser session, it sandboxes BUAs and ensures robustness even under worst-case execution scenarios. This reflects a systems security approach of enforcing defenses beyond the model.
* __Expressiveness.__ Cellmate features a policy language that can express a wide range of common security requirements. This flexibility allows web developers to design policies tailored to the needs of their users.
* __Agent-Agnostic and Lightweight.__ Cellmate is implemented as a lightweight browser extension that is agnostic to the choice of agent. Users can freely adopt their preferred agents while enabling Cellmate with minimal overhead. Our current prototype is a Chrome extension, and we plan to extend support to other mainstream browsers, such as Firefox, allowing users to freely combine their choice of browser and agent.

### Cellmate vs. CaMeL
Cellmate is one example of system-level defenses against prompt injection, specifically designed for BUAs. Existing system-level defenses, such as CaMeL [4], are limited to tool-using agents, where each action is modeled as a discrete tool call with a fixed description and importantly, semantics. BUAs, by contrast, interact with web applications in ways that are far more complex and dynamic than tool-using agents, making existing approaches insufficient. Cellmate is the first system-level defense that identifies and addresses these unique challenges, enforcing fine-grained sandboxing policies over browser interactions.

Try [Cellmate](https://github.com/earlence-security/cellmate) today!
If you encounter any issues, please email us at [lumeng@ucsd.edu](mailto:lumeng@ucsd.edu) or [hefeng@ucsd.edu](mailto:hefeng@ucsd.edu).

## Acknowledgment

We thank Prashant Kulkarni for insightful comments.

## References

[1] Sizhe Chen, Julien Piet, Chawin Sitawarin, and David Wagner. StruQ: Defending Against Prompt Injection with Structured Queries. USENIX Security 2025.
[2] Sizhe Chen, Arman Zharmagambetov, Saeed Mahloujifar, Kamalika Chaudhuri, David Wagner, and Chuan Guo. SecAlign: Defending against prompt injection with preference optimization, 2025.
[3] Sizhe Chen, Arman Zharmagambetov, David Wagner, and Chuan Guo. Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks, 2025.
[4] Edoardo Debenedetti, Ilia Shumailov, Tianqi Fan, Jamie Hayes, Nicholas Carlini, Daniel Fabian, Christoph Kern, Chongyang Shi, Andreas Terzis, and Florian Tramèr. Defeating Prompt Injections by Design, 2025.
[5] Keegan Hines, Gary Lopez, Matthew Hall, Federico Zarfati, Yonatan Zunger, and Emre Kiciman. Defending Against Indirect Prompt Injection Attacks With Spotlighting, 2024.
[6] Yupei Liu, Yuqi Jia, Jinyuan Jia, Dawn Song, and Neil Zhenqiang Gong. DataSentinel: A Game-Theoretic Detection of Prompt Injection Attacks. In 2025 IEEE Symposium on Security and Privacy (SP), IEEE, 2025.  
[7] Anselm Paulus, Arman Zharmagambetov, Chuan Guo, Brandon Amos, and Yuandong Tian. AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs. arXiv preprint, 2024.  
[8] Learn Prompting. Sandwich Defense. https://learnprompting.org/docs/prompt_hacking/defensive_measures/sandwich_defense, 2023.  
[9] Tianneng Shi, Kaijie Zhu, Zhun Wang, Yuqi Jia, Will Cai, Weida Liang, Haonan Wang, Hend Alzahrani, Joshua Lu, Kenji Kawaguchi, et al. PromptArmor: Simple yet Effective Prompt Injection Defenses. arXiv preprint, 2025.  
[10] Eric Wallace, Kai Xiao, Reimar Leike, Lilian Weng, Johannes Heidecke, and Alex Beutel. The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions. arXiv preprint, 2024.  
[11] Andy Zou, Zifan Wang, Nicholas Carlini, Milad Nasr, J Zico Kolter, and Matt Fredrikson. Universal and Transferable Adversarial Attacks on Aligned Language Models. arXiv preprint, 2023.  
[12] Nishit V Pandya, Andrey Labunets, Sicun Gao, and Earlence Fernandes. May I have your Attention? Breaking Fine-Tuning based Prompt Injection Defenses using Architecture-Aware Attacks. arXiv preprint, 2025.

